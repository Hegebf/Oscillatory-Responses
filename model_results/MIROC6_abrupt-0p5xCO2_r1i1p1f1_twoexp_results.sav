{"__class__": "lmfit.ModelResult", "__version__": "1", "model": {"__class__": "Tuple", "value": [{"__class__": "Tuple", "value": ["twoexp_function", null, "twoexp_function", "", {"__class__": "List", "value": ["t"]}, {"__class__": "List", "value": ["S1", "S2", "tau1", "tau2"]}, {"__class__": "Dict", "S1": {"__class__": "Dict", "value": 4, "min": 0, "max": 10.0}, "S2": {"__class__": "Dict", "value": 2, "min": 0, "max": 10.0}, "tau1": {"__class__": "Dict", "value": 4, "min": 0, "max": 8}, "tau2": {"__class__": "Dict", "value": 20, "min": 8, "max": 1000}}, "raise", {"__class__": "Dict"}]}, null, null]}, "params": [["S1", 1.0015850215054678, true, null, 0, 10.0, null, 0.02662063932560075, {"S2": 0.8264764816496898, "tau1": 0.5920829442440363, "tau2": 0.8362756730534181}, 4, null], ["S2", 2.4771732770812127, true, null, 0, 10.0, null, 8.754337389745539, {"S1": 0.8264764816496822, "tau1": 0.45651223310736344, "tau2": 0.9998095323603823}, 2, null], ["tau1", 3.005109088816054, true, null, 0, 8, null, 0.3222462728664125, {"S1": 0.592082944244037, "S2": 0.45651223310736344, "tau2": 0.46302904162292285}, 4, null], ["tau2", 999.999979015446, true, null, 8, 1000, null, 335.15106710985896, {"S1": 0.8362756730534138, "S2": 0.9998095323603823, "tau1": 0.46302904162292285}, 20, null]], "unique_symbols": {"little_endian": 1, "S2": 2.4771732770812127, "pi": 3.141592653589793, "nan": NaN, "tau2": 999.999979015446, "False": 0, "NAN": NaN, "tau1": 3.005109088816054, "S1": 1.0015850215054678, "gamfcn": {"__class__": "Callable", "__name__": "gamma", "pyversion": "3.8", "value": null, "importer": "scipy.special._ufuncs"}, "infty": Infinity, "wofz": {"__class__": "Callable", "__name__": "wofz", "pyversion": "3.8", "value": null, "importer": "scipy.special._ufuncs"}, "e": 2.718281828459045, "True": 1, "inf": Infinity, "erfc": {"__class__": "Callable", "__name__": "erfc", "pyversion": "3.8", "value": null, "importer": "scipy.special._ufuncs"}, "None": null, "erf": {"__class__": "Callable", "__name__": "erf", "pyversion": "3.8", "value": null, "importer": "scipy.special._ufuncs"}, "Inf": Infinity, "newaxis": null}, "aborted": 0, "aic": -779.2119917058254, "best_values": {"__class__": "Dict", "S1": 1.0015850215054678, "S2": 2.4771732770812127, "tau1": 3.005109088816054, "tau2": 999.999979015446}, "bic": -767.1428723585657, "chisqr": 0.8219755642414303, "ci_out": null, "col_deriv": 0, "covar": {"__class__": "NDArray", "__shape__": [4, 4], "__dtype__": "float64", "value": [0.0007086584381037211, 0.1926070862327513, 0.005079125397018239, 7.46119776332431, 0.19260708623274955, 76.63842313349673, 1.2878450199757296, 2933.46668109796, 0.005079125397018245, 1.2878450199757296, 0.10384266037629437, 50.007683899021764, 7.461197763324272, 2933.46668109796, 50.007683899021764, 112326.23778487719]}, "errorbars": 1, "flatchain": null, "ier": 1, "init_values": {"__class__": "Dict", "S1": 4, "S2": 2, "tau1": 4, "tau2": 20}, "lmdif_message": "Both actual and predicted relative reductions in the sum of squares\n  are at most 0.000000", "message": "Fit succeeded.", "method": "leastsq", "nan_policy": "raise", "ndata": 151, "nfev": 92, "nfree": 147, "nvarys": 4, "redchi": 0.005591670505043743, "scale_covar": 1, "calc_covar": 1, "success": 1, "userargs": {"__class__": "Tuple", "value": [{"__class__": "NDArray", "__shape__": [151], "__dtype__": "float64", "value": [-0.0, 0.336969921601792, 0.4946380055624217, 0.6321643255380422, 0.6634577256757552, 0.7290535426628821, 0.9412537384154688, 0.9455962670404006, 1.0619220334249917, 1.0285183478068234, 1.0356783490580597, 1.0642801604681154, 0.9604927213554788, 1.0093986867707372, 0.8800032990803857, 1.0282723329796113, 1.077698018528224, 1.0188924517757414, 0.9922466766076354, 0.9853024527773756, 0.923507805032216, 0.9647978421852486, 1.1277499955926942, 1.153837577755212, 1.0083501819511866, 1.0289098922181663, 1.0505291341921748, 1.129290811690737, 1.130442766801309, 1.0170626675087533, 1.098675682582268, 1.0471671657176105, 0.9492722605146467, 1.1442694908679982, 1.1476178954483205, 1.093771913793887, 1.0073286234950842, 1.040345000680702, 1.14953065715423, 1.221782261998044, 1.2040602533726317, 1.0924817633070347, 1.100590034123229, 1.1781610468486292, 1.164349530492359, 1.2807193104517864, 1.2143653451664704, 1.256113312285379, 1.2474243984847817, 1.1832583243929091, 1.1477476653420808, 1.0268805177860827, 0.9297368134283488, 1.0727717136890078, 1.2140937434699026, 1.2313750101552614, 1.1545928812133184, 1.153959816903921, 1.1666565055886622, 1.092027394932927, 1.2599713655373534, 1.2109854884182027, 1.264259717310722, 1.2312526068993748, 1.161209999532559, 1.0909318491549698, 1.07728376996306, 1.1325021742554782, 1.166697114291367, 1.0628440258213914, 1.1132978164007454, 1.1771348796593202, 1.1944718044950378, 0.9523583836401032, 0.9663030024964314, 1.2150802246607668, 1.1753582425112086, 1.1643854446776911, 1.1863156155243928, 1.1446805701004903, 1.2052243876304942, 1.1348487416336184, 1.126513836977722, 1.2180888962024028, 1.0868297922459649, 1.1786166048528344, 1.3056993789014086, 1.2394687164068046, 1.2450821688410088, 1.2559406633446315, 1.2380752374203323, 1.1966925824622194, 1.2465277142122773, 1.2386948173466976, 1.2042677109182025, 1.2674855814049693, 1.1020256919823623, 1.0201316247697036, 1.1364406152809463, 1.2595471411721633, 1.2352632865639066, 1.2620095787859211, 1.1528634615389135, 1.2273767203456032, 1.1804975143257934, 1.140782189209176, 1.204017261988554, 1.1446022424266855, 1.2901584495369889, 1.3365244541953984, 1.2648603485989725, 1.2350285042811606, 1.1944948675202909, 1.2747054438102057, 1.3153662283118024, 1.2426966216452795, 1.2572467267753495, 1.3030408530605089, 1.2381836465031029, 1.2600658474228794, 1.2903775081834965, 1.3245417410760183, 1.2936358153544347, 1.3349121234865606, 1.3546050670713612, 1.264012444559853, 1.325357505846796, 1.3084370828698866, 1.3167212671426682, 1.3030109822602185, 1.1886968971849114, 1.3088268873582365, 1.3307790917216948, 1.4250377064752229, 1.3618617513444633, 1.403055579673662, 1.3491424975301811, 1.31475440235738, 1.3986030473317328, 1.4960920243153168, 1.4814530958574323, 1.3665080740861413, 1.297395044843995, 1.219030506731258, 1.29648641686083, 1.3480597836210109, 1.385744204719174, 1.338091700239488, 1.251989472697289, 1.3455544276255296, 1.3480020981526195]}, null]}, "userkws": {"__class__": "Dict", "t": {"__class__": "NDArray", "__shape__": [151], "__dtype__": "float64", "value": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0]}}, "values": {"__class__": "Dict", "S1": 1.0015850215054678, "S2": 2.4771732770812127, "tau1": 3.005109088816054, "tau2": 999.999979015446}, "var_names": {"__class__": "List", "value": ["S1", "S2", "tau1", "tau2"]}, "weights": null, "user_options": null}